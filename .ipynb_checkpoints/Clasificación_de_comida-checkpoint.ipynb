{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-YxvTLdpw56a",
    "outputId": "b3f45499-6af1-4d5e-b6e6-5ca144208717"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yx2njtztw8fz",
    "outputId": "78d1fd80-ec2b-48da-c5bc-f0f761bea05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/AMP-Tech/CNN desde cero\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QfpVmMt7Jm_"
   },
   "source": [
    "Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "qUp9B4SFzkF9",
    "outputId": "92675988-6ceb-445d-c024-556abb2906ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9866 images belonging to 11 classes.\n",
      "Found 3430 images belonging to 11 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Chey\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Epoch 1/20\n",
      " 554/1000 [===============>..............] - ETA: 22:34 - loss: 2.2615 - acc: 0.2359"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.clear_session()\n",
    "data_entrenamiento = './data/entrenamiento'\n",
    "data_validacion = './data/validacion'\n",
    "\"\"\"\n",
    "Parametros\n",
    "\"\"\"\n",
    "epocas=20 #Numero de iteraciones sobre el set de datos durante el entrnamiento\n",
    "longitud, altura = 150, 150 #tamaño de imagen para el entrenamiento\n",
    "batch_size = 32 #numero de imagenes por paso\n",
    "pasos = 1000 #numero de veces que se procesara la información en cada éppoca\n",
    "validation_steps = 300 #Al final de las épocas se realizara una validacion de 300 pasos\n",
    "filtrosConv1 = 32 #Numero de filtros aplicados por combolución (Profundidad)\n",
    "filtrosConv2 = 64 #\n",
    "tamano_filtro1 = (3, 3) #tamaño del filtro usado en cada combolución\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2) #tamaño del filtro de max pooling\n",
    "clases = 11 #numero de clases\n",
    "lr = 0.0004 #coeficiente de aprendizaje\n",
    "\n",
    "\n",
    "##Preparamos nuestras imagenes\n",
    "#preprocesamiento\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255, #reescalar las imágenes rango de pixeles de 0 a 1\n",
    "    shear_range=0.2, #Generar imagenes inclinadas\n",
    "    zoom_range=0.2,  #posibilidad de hacer zoom\n",
    "    horizontal_flip=True)#invertir imagen \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validacion_generador = test_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "#Red neuronal combolucional\n",
    "cnn = Sequential()#red secuencial\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu')) #creacion de la primera capa \n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))#capa de pooling\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\"))#segunda caoa combolucional\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))#segunda capa de pooling\n",
    "#inicia la clasificación\n",
    "cnn.add(Flatten())#transformar la información a una sola dimencion \n",
    "cnn.add(Dense(256, activation='relu'))#256 neuronas, con activación relu\n",
    "cnn.add(Dropout(0.5))#Se apagaran el 50% de las neuronas para evitar sobreajuste, para adaptarse a informacion nueva\n",
    "cnn.add(Dense(clases, activation='softmax'))#realiza la clasificación\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',#parametos que se utilizaran para el algoritmo\n",
    "            optimizer=optimizers.Adam(lr=lr),#optimizador adam\n",
    "            metrics=['accuracy'])#metrica utilizada\n",
    "\n",
    "#entrenamiento\n",
    "cnn.fit_generator(\n",
    "    entrenamiento_generador,#imagenes de entrenamiento\n",
    "    steps_per_epoch=pasos,#numero de pasos\n",
    "    epochs=epocas,#numero de pasos\n",
    "    validation_data=validacion_generador,#imagenes de validazion\n",
    "    validation_steps=validation_steps)#pasos de validación\n",
    "#guardar modelo como archivo\n",
    "target_dir = './modelo/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chey\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 451s 1us/step\n"
     ]
    }
   ],
   "source": [
    "vgg=applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo():\n",
    "    vgg=applications.vgg16.VGG16()\n",
    "    cnn=Sequential()\n",
    "    for capa in vgg.layers:\n",
    "            cnn.add(capa)\n",
    "    cnn.layers.pop()\n",
    "    for layer in cnn.layers:\n",
    "            layer.trainable=False\n",
    "    cnn.add(Dense(11,activation='softmax'))\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9866 images belonging to 11 classes.\n",
      "Found 3430 images belonging to 11 classes.\n",
      "Epoch 1/12\n",
      "  24/1000 [..............................] - ETA: 3:27:00 - loss: 2.3957 - acc: 0.1341"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e2fb9a564628>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepocas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidacion_generador\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0mtarget_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./modelo/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "data_entrenamiento = './data/entrenamiento'\n",
    "data_validacion = './data/validacion'\n",
    "\n",
    "\n",
    "epocas=12\n",
    "longitud, altura = 224, 224\n",
    "batch_size = 32\n",
    "pasos = 1000\n",
    "validation_steps = 300\n",
    "filtrosConv1 = 32\n",
    "filtrosConv2 = 64\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)\n",
    "clases = 20\n",
    "lr = 0.0004\n",
    "\n",
    "\n",
    "##Preparamos nuestras imagenes\n",
    "\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validacion_generador = test_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "##TODO ESTO ES SUSTITUIDO POR LA FUNCION QUE CREA LA RED VGG16\n",
    "'''cnn = Sequential()\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(clases, activation='softmax'))\n",
    "'''\n",
    "\n",
    "\n",
    "##CREAR LA RED VGG16\n",
    "\n",
    "cnn=modelo()\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(lr=lr),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "histoty=cnn.fit_generator(\n",
    "    entrenamiento_generador,\n",
    "    steps_per_epoch=pasos,\n",
    "    epochs=epocas,\n",
    "    validation_data=validacion_generador,\n",
    "    validation_steps=validation_steps)\n",
    "\n",
    "target_dir = './modelo/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1y6LJBXQ7PcV"
   },
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVMYaQFi7Scf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a5cba7d807bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf \n",
    "longitud, altura = 224, 224#tamaño de la imagen\n",
    "modelo = './modelo/modelo.h5'#direccion del modelo\n",
    "pesos_modelo = './modelo/pesos.h5'#direccion de los pesos\n",
    "cnn = tf.keras.models.load_model(modelo)#cargar modelo\n",
    "cnn.load_weights(pesos_modelo)#cargar pesos\n",
    "#funcion de prediccion\n",
    "def predict(file):\n",
    "  x = tf.keras.preprocessing.image.load_img(file, target_size=(longitud, altura))#cargar la imagen\n",
    "  x = tf.keras.preprocessing.image.img_to_array(x)#tansformar imagen a arreglo\n",
    "  x = np.expand_dims(x, axis=0)#en el eje 0 se agrega una dimención extra para procesar la información sin problema\n",
    "  array = cnn.predict(x)#se llama a la red para realizar la predicción\n",
    "  result = array[0]#obtenemos el resultado\n",
    "  answer = np.argmax(result)#nos entrega el indice del valor mas alto\n",
    "  #clasificación del resultado\n",
    "  if answer == 0:\n",
    "    print(file+\" pred: 0\")\n",
    "  elif answer == 1:\n",
    "    print(file+\" pred: 1\")\n",
    "  elif answer == 2:\n",
    "    print(file+\" pred: 2\")\n",
    "  elif answer == 3:\n",
    "    print(file+\" pred: 3\")\n",
    "  elif answer == 4:\n",
    "    print(file+\" pred: 4\")\n",
    "  elif answer == 5:\n",
    "    print(file+\" pred: 5\")\n",
    "  elif answer == 6:\n",
    "    print(file+\" pred: 6\")\n",
    "  elif answer == 7:\n",
    "    print(file+\" pred: 7\")\n",
    "  elif answer == 8:\n",
    "    print(file+\" pred: 8\")\n",
    "  elif answer == 9:\n",
    "    print(file+\" pred: 9\")\n",
    "  elif answer == 10:\n",
    "    print(file+\" pred: 10\")\n",
    "  return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVN8XHrJCuSD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: perro\n",
      "pred: perro\n",
      "pred: gorila\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file='./test/cat.jpg'\n",
    "predict(file)#ingresar direccion de la imagen\n",
    "file='./test/dog.jpg'\n",
    "predict(file)#ingresar direccion de la imagen\n",
    "file='./test/gorilla2.jpg'\n",
    "predict(file)#ingresar direccion de la imagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import scandir, getcwd\n",
    "\n",
    "def ls(ruta = getcwd()):\n",
    "    return [arch.name for arch in scandir(ruta) if arch.is_file()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arq = ls('./data/validacion/pan')   # no especificar ruta para tomar el directorio actual\n",
    "cont0=0\n",
    "cont1=0\n",
    "cont2=0\n",
    "cont3=0\n",
    "cont4=0\n",
    "cont5=0\n",
    "cont6=0\n",
    "cont7=0\n",
    "cont8=0\n",
    "cont9=0\n",
    "cont10=0\n",
    "for i in lista_arq:\n",
    "   p=predict('./data/validacion/pan/'+i)\n",
    "   if(p==0):\n",
    "     cont0=cont0+1\n",
    "   if(p==1):\n",
    "     cont1=cont1+1\n",
    "   if(p==2):\n",
    "     cont2=cont2+1\n",
    "   if(p==3):\n",
    "     cont3=cont3+1\n",
    "   if(p==4):\n",
    "     cont4=cont4+1\n",
    "   if(p==5):\n",
    "     cont5=cont5+1\n",
    "   if(p==6):\n",
    "     cont6=cont6+1\n",
    "   if(p==7):\n",
    "     cont7=cont7+1\n",
    "   if(p==8):\n",
    "     cont8=cont8+1\n",
    "   if(p==9):\n",
    "     cont9=cont9+1\n",
    "   if(p==10):\n",
    "     cont10=cont10+1\n",
    "print(100*cont0/len(lista_arq))\n",
    "print(100*cont1/len(lista_arq))\n",
    "print(100*cont2/len(lista_arq))\n",
    "print(100*cont3/len(lista_arq))\n",
    "print(100*cont4/len(lista_arq))\n",
    "print(100*cont5/len(lista_arq))\n",
    "print(100*cont6/len(lista_arq))\n",
    "print(100*cont7/len(lista_arq))\n",
    "print(100*cont8/len(lista_arq))\n",
    "print(100*cont9/len(lista_arq))\n",
    "print(100*cont10/len(lista_arq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arq = ls('./data/validacion/pan')   # no especificar ruta para tomar el directorio actual\n",
    "lista_arq[0][0]==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arq = ls('./evaluation')   # no especificar ruta para tomar el directorio actual\n",
    "true=0\n",
    "\n",
    "for i in lista_arq:\n",
    "   p=predict('./evaluation/'+i)\n",
    "   if(p==i[0]):\n",
    "     true=true+1\n",
    "print(100*true/len(lista_arq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Clasificación de comida.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
