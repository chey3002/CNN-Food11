{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargas de librerias y datos:\n",
    "Se utilizará CNN VGG19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import os\n",
    "import shutil\n",
    "import multiprocessing as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation, GlobalAveragePooling2D, MaxPooling2D, Conv2D, Input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_dir = '/kaggle/input/food11/training'\n",
    "validation_dir = '/kaggle/input/food11/validation'\n",
    "train_files = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\n",
    "validation_files = [f for f in os.listdir(validation_dir) if os.path.isfile(os.path.join(validation_dir, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción de labels del training y validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "# label extraction\n",
    "train = []\n",
    "y_train = []\n",
    "valid = []\n",
    "y_valid = []\n",
    "\n",
    "for file in train_files:\n",
    "    train.append(file)\n",
    "    label= file.find(\"_\")\n",
    "    y_train.append(int(file[0:label]))\n",
    "for file in validation_files:\n",
    "    valid.append(file)\n",
    "    label= file.find(\"_\")\n",
    "    y_valid.append(int(file[0:label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se crean contenedores donde se colocaran las imagenes de 190x190, para que no se sobrepase la ram, y no crashee el kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnInput = np.ndarray(shape=(len(train), 190,190, 3), dtype=np.float32)\n",
    "print('[INFO] Loading training images')\n",
    "i=0\n",
    "for file in train:\n",
    "    image = cv2.imread(train_dir + \"/\" + file)  \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # do not normalize for this model, keep 0-255\n",
    "    image = image.astype(\"float\")\n",
    "    image = cv2.resize(image, dsize=(190, 190), interpolation=cv2.INTER_CUBIC)\n",
    "    # no normalization for this model, keep 0-255\n",
    "    x = img_to_array(image)\n",
    "    x = x.reshape((1, x.shape[0], x.shape[1],\n",
    "                                   x.shape[2]))\n",
    "\n",
    "    cnnInput[i]=x\n",
    "    i+=1\n",
    "print('[INFO] Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnValidation = np.ndarray(shape=(len(valid), 190,190, 3), dtype=np.float32)\n",
    "print('[INFO] Loading validation images')\n",
    "i=0\n",
    "for file in valid:\n",
    "    image = cv2.imread(validation_dir + \"/\" + file)  \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # do not normalize for this model, keep 0-255\n",
    "    image = image.astype(\"float\")\n",
    "    image = cv2.resize(image, dsize=(190, 190), interpolation=cv2.INTER_CUBIC)\n",
    "    # no normalization for this model, keep 0-255\n",
    "    x = img_to_array(image)\n",
    "    x = x.reshape((1, x.shape[0], x.shape[1],\n",
    "                                   x.shape[2]))\n",
    "\n",
    "    cnnValidation[i]=x\n",
    "    i+=1\n",
    "print('[INFO] Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usamos una codificación activa en lugar del número de la clase para las etiquetas. Para obtener un resultado de probabilidades de pertenecer a cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2 = to_categorical(y_train)\n",
    "y_valid_2 = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG19(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make explained variable hot-encoded\n",
    "y_train_hot_encoded = to_categorical(y_train)\n",
    "y_test_hot_encoded = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get layers and add average pooling layer\n",
    "x = vgg_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add fully-connected layer\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# add output layer\n",
    "predictions = Dense(11, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg_model.input, outputs=predictions)\n",
    "\n",
    "# freeze pre-trained model area's layer\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# update the weight that are added\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit(cnnInput, y_train_hot_encoded)\n",
    "\n",
    "# choose the layers which are updated by training\n",
    "layer_num = len(model.layers)\n",
    "for layer in model.layers[:21]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model.layers[21:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# training\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#history= model.fit(cnnInput,y_train_hot_encoded, batch_size=64, shuffle=True,\n",
    "#                    validation_data=(cnnValidation, y_test_hot_encoded),\n",
    "#                  class_weight=class_weights, epochs=100)\n",
    "#history = model.fit(cnnInput, y_train_hot_encoded, batch_size=256, epochs=50, shuffle=True,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "#history = model.fit(cnnInput, y_train_hot_encoded, batch_size=256, epochs=50, shuffle=True,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte, realizamos el aumento de datos. El aumento de datos es una forma de crear nuevos datos con modificaciones:\n",
    "\n",
    "* diferentes orientaciones (horizontal_flip y vertical_flip)\n",
    "* Con desplazamiento (desplazamiento aleatorio de imágenes horizontalmente o desplazamiento aleatorio de imágenes verticalmente)\n",
    "* Zoom \n",
    "* Utilizamos este generador de imágenes para capacitación y validación, pero para el generador de imágenes de validación, utilizamos las imágenes originales del conjunto de datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=[.6, 1],\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True)\n",
    "train_generator = train_datagen.flow(cnnInput, y_train, batch_size=64, seed=11)\n",
    "valid_datagen = ImageDataGenerator()\n",
    "valid_generator = valid_datagen.flow(cnnValidation, y_valid, batch_size=64, seed=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(cnnInput)\n",
    "valid_datagen.fit(cnnValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hystory=model.fit_generator(train_datagen.flow(cnnInput, y_train_hot_encoded, batch_size=64), shuffle=True,\n",
    "                    validation_data=valid_datagen.flow(cnnValidation, y_test_hot_encoded, batch_size=64),\n",
    "                  class_weight=class_weights, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelo.h5')\n",
    "model.save_weights('pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(hystory.history['accuracy'],'r')  \n",
    "plt.plot(hystory.history['val_accuracy'],'g')  \n",
    "plt.xticks(np.arange(0, 21, 1.0))  \n",
    "plt.rcParams['figure.figsize'] = (12,10 )  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.figure(1)  \n",
    "plt.plot(hystory.history['loss'],'r')  \n",
    "plt.plot(hystory.history['val_loss'],'g')  \n",
    "plt.xticks(np.arange(0, 21, 1.0))  \n",
    "plt.rcParams['figure.figsize'] = (12, 10)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.title(\"Training Loss vs Validation Loss\")  \n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prueba del modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definición de la función de preducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf \n",
    "longitud, altura = 190, 190#tamaño de la imagen\n",
    "#modelo = './modelo/modelo.h5'#direccion del modelo\n",
    "#pesos_modelo = './modelo/pesos.h5'#direccion de los pesos\n",
    "#cnn = tf.keras.models.load_model(modelo)#cargar modelo\n",
    "#cnn.load_weights(pesos_modelo)#cargar pesos\n",
    "#funcion de prediccion\n",
    "def predict(file):\n",
    "  x = tf.keras.preprocessing.image.load_img(file, target_size=(longitud, altura))#cargar la imagen\n",
    "  x = tf.keras.preprocessing.image.img_to_array(x)#tansformar imagen a arreglo\n",
    "  x = np.expand_dims(x, axis=0)#en el eje 0 se agrega una dimención extra para procesar la información sin problema\n",
    "  array = model.predict(x)#se llama a la red para realizar la predicción\n",
    "  result = array[0]#obtenemos el resultado\n",
    "  answer = np.argmax(result)#nos entrega el indice del valor mas alto\n",
    "  #clasificación del resultado\n",
    "  if answer == 0:\n",
    "    print(file+\" pred: 0\")\n",
    "  elif answer == 1:\n",
    "    print(file+\" pred: 1\")\n",
    "  elif answer == 2:\n",
    "    print(file+\" pred: 2\")\n",
    "  elif answer == 3:\n",
    "    print(file+\" pred: 3\")\n",
    "  elif answer == 4:\n",
    "    print(file+\" pred: 4\")\n",
    "  elif answer == 5:\n",
    "    print(file+\" pred: 5\")\n",
    "  elif answer == 6:\n",
    "    print(file+\" pred: 6\")\n",
    "  elif answer == 7:\n",
    "    print(file+\" pred: 7\")\n",
    "  elif answer == 8:\n",
    "    print(file+\" pred: 8\")\n",
    "  elif answer == 9:\n",
    "    print(file+\" pred: 9\")\n",
    "  elif answer == 10:\n",
    "    print(file+\" pred: 10\")\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Función de creación de ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import scandir, getcwd\n",
    "def ls(ruta = getcwd()):\n",
    "    return [arch.name for arch in scandir(ruta) if arch.is_file()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prueba de la evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arq = ls('/kaggle/input/food11/evaluation') \n",
    "true=0\n",
    "for i in lista_arq:\n",
    "   p=predict('/kaggle/input/food11/evaluation/'+i)\n",
    "   if(str(p)==i[0]):\n",
    "     true=true+1\n",
    "print(100*true/len(lista_arq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
